{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5492e1e4",
   "metadata": {},
   "source": [
    "## Install `PADL-Extensions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install padl-extensions[pytorch_lightning]\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These might be useful if there are errors regarding ipywidgets while downloading torchvision.datasets\n",
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3da65d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "\n",
    "import padl\n",
    "from padl import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd944ba",
   "metadata": {},
   "source": [
    "## Using PADL with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de455b",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "MNIST dataset available through torchvision is used in this notebook. The dataset can be separately downloaded from MNIST website or can be loaded as given below. \n",
    "\n",
    "More details on torchvision's MNIST dataset can be found here: https://pytorch.org/vision/stable/datasets.html#mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "mnist_test_dataset = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a4df6",
   "metadata": {},
   "source": [
    "## 1. Model Definition\n",
    "\n",
    "We will build a simple `Unet` to classify `MNIST` handwritings. In the cell below, a simple `torch.nn.Module` is defined with the decorator `@transform`. This is enough to wrap the pytorch model into a `padl.Transform` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision.models.resnet \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv 1\n",
    "        # size : input: 28x28x1 -> output : 26 x 26 x 32\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 2\n",
    "        # size : input: 26x26x32 -> output : 24 x 24 x 32\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 3\n",
    "        # size : input: 24x24x32 -> output : 12 x 12 x 32\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 4\n",
    "        # size : input : 12 x 12 x 32 -> output : 8 x 8 x 64\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # Conv 5\n",
    "        # size : input: 8x8x64 -> output : 4 x 4 x 64 -> Linearize = 1024\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # dropout layer \n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "\n",
    "        # FC 1 \n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "\n",
    "        # FC 2\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform\n",
    "def convert_to_tensor(img):\n",
    "    arr = np.asarray(img)\n",
    "    return torch.tensor(arr).type(torch.FloatTensor)\n",
    "\n",
    "preprocess = (\n",
    "    convert_to_tensor / convert_to_tensor\n",
    "    >> padl.same.reshape(-1, 28, 28) / padl.Identity()\n",
    ")\n",
    "\n",
    "simplenet = SimpleNet()\n",
    "loss_func = transform(F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device to be used: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a674e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = (\n",
    "    preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> transform(F.nll_loss)\n",
    ")\n",
    "\n",
    "train_model.pd_to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404e855",
   "metadata": {},
   "source": [
    "## 2 Converting a PADL model into a Lightning Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b98ca",
   "metadata": {},
   "source": [
    "### 2.1 Directly Initialize the class PadlLightning\n",
    "If your `train_model` has the loss function as the final step you can directly build the `PadlLightning` object by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl_ext.pytorch_lightning import PadlLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35407731",
   "metadata": {},
   "outputs": [],
   "source": [
    "PadlLightning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 0\n",
    "\n",
    "padl_lightning_module = PadlLightning(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "# pad_lightning is a LightningModule !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de0b17",
   "metadata": {},
   "source": [
    "### 2.2 Inherit from PADLLightning\n",
    "The class `PADLLightning` is already a `LightningModule` so inherting from it allows for all the regular customizations available in Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "learning_rate = 0.01\n",
    "\n",
    "class MyModule(PadlLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "padl_lightning_module = MyModule(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "# pad_lightning is a LightningModule !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd07cd",
   "metadata": {},
   "source": [
    "## 3. Training and validating the `train_model` with the PADL-Pytorch Lightning Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2baae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "log_interval = 10\n",
    "nepoch = 2\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1 if device == 'cuda' else 0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=nepoch,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=log_interval\n",
    ")\n",
    "trainer.fit(padl_lightning_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
