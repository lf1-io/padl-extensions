{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5492e1e4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may also need to install torchvision\n",
    "# !pip install torchvision\n",
    "# !pip install pytorch_lightning\n",
    "\n",
    "# These might be useful if there are errors regarding ipywidgets while downloading torchvision.datasets\n",
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "\n",
    "import padl\n",
    "from padl import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd944ba",
   "metadata": {},
   "source": [
    "## Using PADL with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de455b",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "MNIST dataset available through torchvision is used in this notebook. The dataset can be separately downloaded from MNIST website or can be loaded as given below. \n",
    "\n",
    "More details on torchvision's MNIST dataset can be found here: https://pytorch.org/vision/stable/datasets.html#mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "mnist_test_dataset = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a4df6",
   "metadata": {},
   "source": [
    "### 1. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision.models.resnet \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv 1\n",
    "        # size : input: 28x28x1 -> output : 26 x 26 x 32\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 2\n",
    "        # size : input: 26x26x32 -> output : 24 x 24 x 32\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 3\n",
    "        # size : input: 24x24x32 -> output : 12 x 12 x 32\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 4\n",
    "        # size : input : 12 x 12 x 32 -> output : 8 x 8 x 64\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # Conv 5\n",
    "        # size : input: 8x8x64 -> output : 4 x 4 x 64 -> Linearize = 1024\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # dropout layer \n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "\n",
    "        # FC 1 \n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "\n",
    "        # FC 2\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform\n",
    "def convert_to_tensor(img):\n",
    "    arr = np.asarray(img)\n",
    "    return torch.tensor(arr).type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "preprocess = (\n",
    "    convert_to_tensor / convert_to_tensor\n",
    "    >> padl.same.reshape(-1, 28, 28) / padl.Identity()\n",
    ")\n",
    "\n",
    "simplenet = SimpleNet()\n",
    "loss_func = transform(F.nll_loss)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device to be used: ', device)\n",
    "\n",
    "train_model = (\n",
    "    preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> transform(F.nll_loss)\n",
    ")\n",
    "\n",
    "train_model.pd_to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404e855",
   "metadata": {},
   "source": [
    "### 2.1 Creating a Lightning Module using PADLLightningModule\n",
    "If your `train_model` has the loss function as the final step you can directly build the `PADLLightning` object by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from padl_ext.pytorch_lightning import PADLLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35407731",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADLLightning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 0\n",
    "\n",
    "padl_lightning_module = PADLLightning(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de0b17",
   "metadata": {},
   "source": [
    "### 2.2 Inherit from PADLLightningModule to customize in the same way as a LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "learning_rate = 0.01\n",
    "\n",
    "class MyModule(PADLLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "padl_lightning_module = MyModule(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd07cd",
   "metadata": {},
   "source": [
    "### 3. Training and validating the `train_model` with the PADL-Pytorch Lightning Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2baae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "log_interval = 10\n",
    "nepoch = 2\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1 if device == 'cuda' else 0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=nepoch,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=log_interval\n",
    ")\n",
    "trainer.fit(padl_lightning_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
