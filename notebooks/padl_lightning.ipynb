{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5492e1e4",
   "metadata": {},
   "source": [
    "## Install `PADL-Extensions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install padl-extensions[pytorch_lightning]\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74765ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These might be useful if there are errors regarding ipywidgets while downloading torchvision.datasets\n",
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac4c58",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d969c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "import padl\n",
    "from padl import transform\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd944ba",
   "metadata": {},
   "source": [
    "## Using PADL with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de455b",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "MNIST dataset available through torchvision is used in this notebook. The dataset can be separately downloaded from MNIST website or can be loaded as given below. \n",
    "\n",
    "More details on torchvision's MNIST dataset can be found here: https://pytorch.org/vision/stable/datasets.html#mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "mnist_test_dataset = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a4df6",
   "metadata": {},
   "source": [
    "## 1. Model Definition\n",
    "\n",
    "We will build a simple `Unet` to classify `MNIST` handwritings. In the cell below, a simple `torch.nn.Module` is defined with the decorator `@transform`. This is enough to wrap the pytorch model into a `padl.Transform` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee59c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision.models.resnet \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv 1\n",
    "        # size : input: 28x28x1 -> output : 26 x 26 x 32\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 2\n",
    "        # size : input: 26x26x32 -> output : 24 x 24 x 32\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 3\n",
    "        # size : input: 24x24x32 -> output : 12 x 12 x 32\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 4\n",
    "        # size : input : 12 x 12 x 32 -> output : 8 x 8 x 64\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # Conv 5\n",
    "        # size : input: 8x8x64 -> output : 4 x 4 x 64 -> Linearize = 1024\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # dropout layer \n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "\n",
    "        # FC 1 \n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "\n",
    "        # FC 2\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform\n",
    "def convert_to_tensor(img):\n",
    "    arr = np.asarray(img)\n",
    "    return torch.tensor(arr).type(torch.FloatTensor)\n",
    "\n",
    "preprocess = (\n",
    "    convert_to_tensor / convert_to_tensor\n",
    "    >> padl.same.reshape(-1, 28, 28) / padl.Identity()\n",
    ")\n",
    "\n",
    "simplenet = SimpleNet()\n",
    "loss_func = transform(F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9505378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to be used:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device to be used: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d949879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"train_model\":\n",
       "\n",
       "   \u001b[32m   │└────────────────────┐\n",
       "      │                     │\n",
       "      ▼ img                 ▼ img\u001b[0m\n",
       "   \u001b[1m0: \u001b[0mconvert_to_tensor   \u001b[32m/\u001b[0m convert_to_tensor\n",
       "   \u001b[32m   │                     │\n",
       "      ▼ args                ▼ args\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mreshape(-1, 28, 28) \u001b[32m/\u001b[0m Identity()       \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mBatchify(dim=0)    \n",
       "   \u001b[32m   │└────────────────────┐\n",
       "      │                     │\n",
       "      ▼ x                   ▼ args\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mSimpleNet()         \u001b[32m/\u001b[0m type(torch.int64)\n",
       "   \u001b[32m   │\n",
       "      ▼ (input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n",
       "   \u001b[1m4: \u001b[0mnll_loss           "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model = (\n",
    "    preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> transform(F.nll_loss)\n",
    ")\n",
    "\n",
    "train_model.pd_to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f608f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"infer_model\":\n",
       "\n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m0: \u001b[0m__getitem__(0)            \n",
       "   \u001b[32m   │\n",
       "      ▼ img\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mconvert_to_tensor         \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mBatchify(dim=0)           \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m3: \u001b[0munsqueeze(1)              \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m4: \u001b[0mSimpleNet()               \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m5: \u001b[0mlambda x: x.max(1).indices"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_preprocess =(\n",
    "    padl.same[0]\n",
    "    >> convert_to_tensor\n",
    ")\n",
    "infer_model = (\n",
    "    infer_preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> padl.same.unsqueeze(1) \n",
    "    >> simplenet\n",
    "    >> padl.transform(lambda x: x.max(1).indices)\n",
    ")\n",
    "infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404e855",
   "metadata": {},
   "source": [
    "## 2. Converting a PADL model into a Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e5f0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl_ext.pytorch_lightning import DefaultPadlLightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d0d670",
   "metadata": {},
   "source": [
    "## 2.1 Use the DefaultPadlLightning class\n",
    "If your `train_model` has the loss function as the final step you can initialize the `DefaultPadlLightning` object by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35407731",
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultPadlLightning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04a8761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "padl_lightning_module = DefaultPadlLightning(\n",
    "    train_model,  # train_model with the loss function\n",
    "    learning_rate=1e-3,\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "# pad_lightning is a LightningModule !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fe1f0",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81528f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | SimpleNet | SimpleNet | 214 K \n",
      "----------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0245b40520b042f396a6b124f25140ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_10/checkpoints/epoch=0-step=9.padl/8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_10/checkpoints/epoch=0-step=19.padl/8.pt\n"
     ]
    }
   ],
   "source": [
    "log_interval = 10\n",
    "nepoch = 1\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1 if device == 'cuda' else 0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=nepoch,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=log_interval\n",
    ")\n",
    "trainer.fit(padl_lightning_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5874c6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar at 0x18a820160>,\n",
       " <pytorch_lightning.callbacks.model_summary.ModelSummary at 0x18a820700>,\n",
       " <pytorch_lightning.callbacks.gradient_accumulation_scheduler.GradientAccumulationScheduler at 0x18a820490>,\n",
       " <padl_ext.pytorch_lightning.prepare.OnCheckpointSavePadl at 0x18a7f0400>,\n",
       " <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint at 0x18a679af0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de0b17",
   "metadata": {},
   "source": [
    "## 2.2 Inherit from BasePadlLightning\n",
    "The class `BasePadlLightning` is already a `LightningModule` so inherting from it allows for all the regular customizations available in Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7cf53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl_ext.pytorch_lightning import BasePadlLightning, OnCheckpointSavePadl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93212691",
   "metadata": {},
   "outputs": [],
   "source": [
    "BasePadlLightning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(BasePadlLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb3f1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 0\n",
    "\n",
    "padl_lightning_module = MyModule(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "# pad_lightning is a LightningModule !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c73710",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d080afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | SimpleNet | SimpleNet | 214 K \n",
      "----------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aea4e2c55dd4d5991c605d3fc117744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_12/checkpoints/epoch=0-step=9.padl/8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_12/checkpoints/epoch=0-step=19.padl/8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_12/checkpoints/epoch=0-step=29.padl/8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_12/checkpoints/epoch=0-step=39.padl/8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_12/checkpoints/epoch=0-step=49.padl/8.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e73bfece80461bbc9cd72a5de84040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_interval = 10\n",
    "nepoch = 1\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "# model_checkpoint = ModelCheckpoint(monitor=\"val_loss\", every_n_epochs=1, save_top_k=1)\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"val_loss\")\n",
    "callbacks = [early_stop, model_checkpoint, OnCheckpointSavePadl()]\n",
    "# callbacks = [OnCheckpointSavePadl()]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    gpus=1 if device == 'cuda' else 0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=nepoch,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=log_interval\n",
    ")\n",
    "trainer.fit(padl_lightning_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb8939",
   "metadata": {},
   "source": [
    "## 4. Infer a few images from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b2abb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform\n",
    "def plot_image(img_tensor):\n",
    "    fig= plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img_tensor, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    return fig\n",
    "\n",
    "@transform\n",
    "def img_to_array(img):\n",
    "    return np.asarray(img)\n",
    "\n",
    "convert_plot = (\n",
    "    img_to_array\n",
    "    >> plot_image\n",
    ")\n",
    "\n",
    "plot_datapoint = (convert_plot - 'image')/ (padl.Identity() - 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd69eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    data_point = mnist_test_dataset[np.random.randint(len(mnist_test_dataset))]\n",
    "    output = plot_datapoint(data_point)\n",
    "    plt.show()\n",
    "    print(f'Prediction: {infer_model.infer_apply(data_point).item()}')\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b16d45",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98bfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da47618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading torch module from test/lightning_logs/version_12/checkpoints/epoch=0-step=49.padl/8.pt\n"
     ]
    }
   ],
   "source": [
    "test = load('test/lightning_logs/version_12/checkpoints/epoch=0-step=49.padl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00f18067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplenet'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[3][0].pd_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f125ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_preprocess =(\n",
    "    padl.same[0]\n",
    "    >> convert_to_tensor\n",
    ")\n",
    "trained_net = test[3][0]\n",
    "infer_model = (\n",
    "    infer_preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> padl.same.unsqueeze(1) \n",
    "    >> trained_net\n",
    "    >> padl.transform(lambda x: x.max(1).indices)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "500b536e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEeklEQVR4nO2dTSgtYRzG33PdSFjIRxGxkAULbOVjJzufpZRkpywopVgoViwlURaSLGVhY2HhoyyshKLExmckrAg5d3VP93lv5ty55sz5eJ7fap7mzJy3fr3zPzPznzmBYDBoBAc/oj0A4R+STYRkEyHZREg2EZJNxE+nlYFAQOdlcUYwGAx8tU4zmwjJJkKyiZBsIiSbCMkmQrKJkGwiJJsIySZCsomQbCIkmwjJJkKyiXC8nx1JlpaWIHd2dkI+OjqCPDc357i/09NTyBsbG98YXWKimU2EZBMRtcP42dkZZPvJlPLycsjT09OO+3t6eoJ8eXn55Wd3dnYgz8/PQz44OHD8rnhFM5sIySZCsokIOD3FGclW4uTkZMitra2Qp6amIGdlZXn23YEAdtve3d1BDnfaNjw8DNnp94HfqJVYGGMkmwrJJiJqNTscQ0NDkDMyMlxt39XVBbmgoCC0bNdst2+fOD4+htzc3AzZvobgJ6rZwhgj2VRINhExW7O/S25uLuTu7u7Qcm1tLayzs9vfB/f395DHx8chz87Outrfd1DNFsYYyaZCsolI2JrthpqaGshjY2OQ6+vrHbf/+PiAPDAwADlcS5WXqGYLY4xkUyHZREStBy2WsO9H5+TkuNr++voasp812g2a2URINhGSTYRqtjGmpaUFcllZmavtBwcHvRxOxNDMJkKyiZBsIlSzDd7r/hd2d3chb25uejiayKGZTYRkEyHZRFDW7Lq6Osj5+fmutn98fHTMsYpmNhGSTQRNW9Kfh+6trS1Y9/n56WpfxcXFkC8uLv57XF6jtiRhjJFsKiSbiIQ99UpLS4Pc398fWrZrtP27xW4NtluLb29vvRii72hmEyHZREg2EXFznp2amgrZHndKSgpk+7HZvr6+0HK412zc3NxALiwsdDfYKKLzbGGMkWwqJJuImD3PLikpgby4uAj59fUVcrjHat2wvb3tuG/72nq8oJlNhGQTIdlERK1mV1dXQ15eXoZsn1dnZ2dHfEy/6ejogJyUlAR5b28P8svLS8TH5AWa2URINhGSTYRvNdv+q6ampibIbtt5w/H29gb5z3vQ9usqMzMzHffV3t4O+fz8HPLIyMj/DNF3NLOJkGwiJJsI32q2/Zpnr2v0/v4+5JmZGcgLCwuh5crKSli3trYGOS8vz/G72traID8/P0OenJx03D5aaGYTIdlESDYRvvWgVVRUQF5ZWYFsPz91dXUFeXV1FfLo6Cjk9/d3yG6uV6enp0Pu7e2FPDEx4bi93YduX+e3/7LZfk2Hl6gHTRhjJJsKySYian3jpaWlkO3XPj88PEA+OTmJ1FD+wr52bvek2evt3xs29l9B9fT0QF5fX3c5wq9RzRbGGMmmQrKJiJtnvWKJoqIiyI2NjZDte/UNDQ2QDw8PIVdVVXk2NtVsYYyRbCp0GE8wdBgXxhjJpkKyiZBsIiSbCMkmQrKJkGwiJJsIySZCsomQbCIkmwjJJkKyiXC8ny0SC81sIiSbCMkmQrKJkGwiJJuIX2aANr+cZPxNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAETElEQVR4nO2dTyhsURzHzzyv/I3YSAmxEgtKkWwUSsTCVsqCZMPGVlFWNkoslBWl2GAhQllIKTtSUkLJxp+kNEXm7ab5nvfcN+PdeXNmvt/P6n67Z2ZOfTrz63fn3LmBUChkBAc/Ej0B8f+QbCIkmwjJJkKyiZBsIn56nQwEAurLkoxQKBT46pxWNhGSTYRkEyHZREg2EZJNhGQT4dlns9DV1QV5Y2MDcjAYhJybmwv5/f09PhPzGa1sIiSbCMkmgrJm19XVQR4eHob8+fkJubu7G3Ky1GgbrWwiJJsIySYi4LWVOJV+z87MzAwfb29vw7mmpibIDw8PkCsrKyE/PT35PDv/0O/Zwhgj2VSkbOuVnp4OeXZ2Nnxsf20fHR1BHhgYgOzy13YsaGUTIdlESDYRKdt6NTc3Q97b2wsf261VT08P5MPDw/hNLM6o9RLGGMmmQrKJSJk+u6GhAfL6+vqXY0dHRyEnc42OBa1sIiSbCMkmImn7bLtG7+7uQs7KyoJ8fn4ePq6trYVzHx8fPs8ucajPFsYYyaZCsolI2pp9c3MDubi4GPLr6yvkxsbG8HFk/U41VLOFMUayqZBsIpLm2nhnZyfkgoICz/Fra2uQU7lOR4tWNhGSTYRkE+Fsn52fnw/5+PgYckVFBeTr62vIra2tkK+urvybnMOozxbGGMmmQrKJcLbPrq+vh2zXaJvl5WXI8azR9r1gfX19nuPn5+chr6ys+D6naNDKJkKyiZBsIpyt2dXV1TGNX1xcjNNMjKmqqoLc0dEBOfK38j9RU1MD+fT0FPLZ2dn3JxcDWtlESDYRzn6Nt7e3xzT+8fHRt8+enp6GPDg4CDknJyem91tYWIB8cXHxvYn9I1rZREg2EZJNhDM1u6ioCHJJSYnn+N7eXshvb29Rf5b92vHxcciFhYWQs7Ozo35vY37/V+OtrS3IifpXY61sIiSbCMkmwpmafX9/D/n29hZyeXk55IyMDMj29qq0tDTIkb3y2NgYnLu8vIQ8MjICeXV1FbJ9O/Dz8zNk+8kE+/v7xgW0somQbCIkmwhnanastLW1Qd7Z2YHc398PeXJy8sv3Ki0thdzS0uL52ScnJ5CnpqYgb25uer4+UWhlEyHZREg2Ec7e/jM0NAR5bm7Oc7x9+09ZWZlvc5mZmYFs9+n2tfBEott/hDFGsqmQbCKcrdl5eXmQl5aWINvbef+Fg4MDyPYeNPvatstP2VXNFsYYyaZCsolw9tr4y8sLZPs217/VbHtPWuS+M/t2m7u7O8jBYDDqeSYTWtlESDYRkk2Es322vefMfiyEfe3bfizyxMQE5MjHM6Yy6rOFMUayqZBsIpyt2eJ7qGYLY4xkUyHZREg2EZJNhGQTIdlESDYRkk2EZBMh2URINhGSTYRkEyHZREg2EZJNhGQTIdlESDYRkk2EZBPhuZVYpBZa2URINhGSTYRkEyHZREg2Eb8ARSskrB9AFfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 6\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEn0lEQVR4nO2dSyh1URiGv/MTSjFQlHLLdSQZUjojJhIZUDI1kpSJWxgwNqBkosxIBkcGLklJlFwmLjGQDEyQMnArnX8m39d/9nH+s8/N+z6j87ZvS0/L11p77b09fr9fCAZ/Yt0AEj0oGwjKBoKygaBsICgbiGSnjR6Ph+OyBMPv93sCbWPPBoKygaBsICgbCMoGgrKBoGwgKBsIygaCsoGgbCAoGwjKBoKygaBsICgbCMoGgrKBcFyWlMh4vd6A27a3t1VeW1tTub6+XuXJyUmVHx8fHa+9vLys8tXVleP+0YI9GwjKBoKygfA4PcUZzaXEHR0dKvf396ucl5cX0vlSUlICbktNTVXZ7SdZW1tbVfb5fK6e3wkuJSYiQtlQUDYQMavZExMTKvf19amcnKynAI6Pj1Wurq7+72t7PLqsuV2zDw4OVK6pqXH1/E6wZhMRoWwoKBuImM2Nd3Z2qmxrtOXi4kLl0tJSlbe2thyP39jY+Pqdlpamtq2vrzseaxkZGVG5ra1N5aqqKpWbmppUXllZCel6bsGeDQRlA0HZQMRsnH17e6tybm6u4/7d3d0q7+7uqnx6eupOw35ARkaGymVlZY7739zcqPzw8OB2k77gOJuICGVDQdlAxGycPTc3p/Lw8LDj/peXlypHs0Zbnp+fVT48PIxRS0KDPRsIygaCsoGIWc2+vr4Oaf+CggKVKyoqHPe/v78PuC3Yuu/fCns2EJQNBGUDEbO58eLiYpXtPd7y8vKwzn9ychJw2/n5ucr7+/sqLy4uqvz09BRWW6IJ58aJiFA2FJQNRNw869XS0qLy0tJSxK4VbN24nYefnp5WeX5+XuWXlxcXWxcerNlERCgbil/7mo1wsMO+qakplZubm1VuaGiIdJNcgT0bCMoGgrKBiJuhl6WkpETlwcFBlRsbG1VeWFhQ2T4e9H3578fHh9pWV1f33+0UERkfH1d5dHQ0rPOFA4deREQoGwrKBiJua7YlKSlJZfvY7evrq8r2EeDvU6T2b7av/Ojq6lI5PT3dsW2fn58q21djra6uOh7vJqzZREQoGwrKBiJhanY0ycnJUXlnZ0dlu6TKYsfdY2NjrrTrJ7BmExGhbCgoGwjW7B9wdnamcrBlznbuvb29XeVIvhqLNZuICGVDQdlAcA3aP+jp6VE5Pz8/pOPv7u5U3tvbC7tNbsCeDQRlA0HZQMRtzc7MzFTZzgfY11NZCgsLVc7Ozv76be9f23PX1taqbD8NFQx7bz2Sr68MBfZsICgbCMoGIm5rtv2Msb2HHKwOVlZWqlxUVPT12+1PPdkaPTs7G9b5IgV7NhCUDQRlAxG3Ndu+2sp+TinUsa+bvL+/qzwwMKCyfS1HvMCeDQRlA0HZQCTMGjSfz6ey1+tVOdjzWN+x42xbg9/e3hyPHxoaUnlmZubH1440XINGRISyoUiYf+OWrKwslXt7e1W2w6Hv2C8NHR0dqby5uRle42II/40TEaFsKCgbiISt2eTfsGYTEaFsKCgbCMoGgrKBoGwgKBsIygaCsoGgbCAoGwjHuXHyu2DPBoKygaBsICgbCMoGgrKB+At1j0l+EMSQSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEbklEQVR4nO2dOyw0URiGv3EJEiISBQqVS2gUeo2EhFohIWhoNKIQCSIo1EoRGneNkFAJgojGpRNUbiEKiQQFsX832e/k39mMmV0z+75Pdd7MObtHHsdnds/MWJFIRAgGaX89AZI8KBsIygaCsoGgbCAoG4gMp4OWZfG8LGREIhEr1jGubCAoGwjKBoKygaBsICgbCMoGwvE8O5Wora212wcHB+pYTk6Oyqurqyp3dnaq/Pn56e/kkgRXNhCUDQRlA5GyNTs/P1/liYkJu52VlaWO/fz8qFxQUKDy9/e3z7P7G7iygaBsICgbiJSp2Zalv8YdGxtTuaGhIebYx8dHlfv6+lT++vryOLtgwJUNBGUDYTldERKmbUkdHR0qz87Oxux7f3+vcn19vco3Nzf+TSzJcFsSERHKhoKygUiZmn13d6dySUlJzL7RX3eKiJyfnydiSn8CazYREcqGgrKBCM3HpWlp+vdyeHhY5aKiIsfxl5eXdvv6+tq/iYUIrmwgKBsIygYiNDW7urpa5ZGREVfjd3Z27Pb7+7svcwobXNlAUDYQlA1EaGp2eXm5q/5bW1sqDw0N+TmdUMKVDQRlA0HZQAS2Zqenp6s8ODjoavzy8rLKb29vnucUdriygaBsICgbiMDuQWtublZ5Y2PDsf/Hx4fKeXl5vs8pDHAPGhERyoaCsoEI7Hl2RUWFq/7m7az8JDs7W+WWlhZX4/f391W+vb31PKffwJUNBGUDQdlABLZm19TUuOr//Pz86/fKzMxUuaenR2Vzj3phYaGr17+6ulJ5dHRU5ej/NxL5BEWubCAoG4jA/hlPJHV1dSqbW5bM2254xTyNXFxcVPn4+NhuJ/K0jCsbCMoGgrKBCGzNvri4ULm9vd2x/8rKiuPxxsZGu725uamOmVug4rG3t6fy5OSkyubdFre3tx1fL3qbNGs28QXKBoKygQhszXbL+vq6ypWVlSpHX+Ibr0YfHh7GHCsicnR0pLL5pIGuri7H1zdpa2uz29GXFvsNVzYQlA0EZQORMjXbfApfaWmpylVVVTHH7u7uqmxuO3p9fXU1l6mpKVf9452H+wVXNhCUDQRlAxHYy3/M21M+PDw49jd/DrPulpWV2W1zW5C5DWl+ft7xvYqLi1UeGBhQube3V2Xzs/K1tTWVW1tb7bbXbUm8/IeICGVDQdlABLZmm3XO/D57bm7Ocby5tXhpaclum0+6Pzs7U9n8Lr27u1tl8ym98T5rPz09VbmpqUnll5cXx/FuYM0mIkLZUFA2EIGt2SbmbTMWFhZUNm/LkUzMzwBmZmZUnp6eVvnp6Slhc2HNJiJC2VBQNhChqdkmubm5Kpv7xPr7+317r5OTE5XHx8dVNs+jvVw+7BXWbCIilA0FZQMR2ppN/g9rNhERyoaCsoGgbCAoGwjKBoKygaBsICgbCMoGgrKBoGwgKBsIygaCsoGgbCAoGwjKBoKygaBsICgbCMoGwnErMUktuLKBoGwgKBsIygaCsoGgbCD+Ad0LHo1FBPNRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 6\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEPUlEQVR4nO2dzSs1YRjG78OrWLGUFIXwN7ARaxRloZCdKBayUlZsxRb5WvpYWCkrJcoKKxZCSXbkIxZy3t3pXI/XMOac84z3un6ruZp3PvR7n7mb59wzk0gmkyY4yPN9AiJ3SDYRkk2EZBMh2URINhF/glYmEgndl/0ykslk4rN1GtlESDYRkk2EZBMh2URINhGSTYRkEyHZREg2EZJNhGQTIdlESDYRkk2EZBMh2URINhGBbUlxYnFxEXJfXx/kqakpyGtra5CPjo6ycVpmZtbY2Aj59vYW8tPTU+D6XKGRTYRkEyHZRCSCnuL02UpcWFgIeWVlBXJHRwfk9/d3yFdXV5C7urpSy+3t7bDOrblhn2ytqamB/Pj4CPnl5QXy7Ows5OXl5VDHC0KtxMLMJJsKySYitjV7enoa8tDQEOS8PPx/6tbsMGRyX9/Z3+7uLuTOzs7U8v39faRjq2YLM5NsKiSbiNjMjY+MjEAeGBjwcyI5oKKiAvLg4GBqeXJyMmvH1cgmQrKJkGwiYlOzi4uLIefn53s6k+yzuroKOZt1Oh2NbCIkmwjJJsLb3HhlZSXk8/PzUNv7nBtfX1+H/Pz8DHl/fx/y/Pz8j88tLJobF2Ym2VRINhHe7rPf3t4g393dQXbvu78i6m/Q6dzc3EDu7u6GfHh4CPn19TVjx84mGtlESDYRkk2Et5p9fX0N2e0D39jYgBy2hkehqKgIclNTE+STkxPIqtkidkg2EZJNRGz7xpubmyEvLS1BLisrg5zLufHNzU3I6c+R+UZz48LMJJuK2F7GXRoaGiBXV1dDdv+OtrY2yK2trZ/uO+xl3H1Nxs7ODuT+/v7A7bOJLuPCzCSbCskm4tfU7KjU1dWllre2tmCd+5qMqD+X+myDVs0WZibZVEg2ETQ1O53a2lrIPT09kMfGxiLtv6CgINL2UVDNFmYm2VRINhHe2pJKSkogDw8PQ768vIScyVc+np2dQa6vr8/YvuOMRjYRkk2EZBORs5pdWloK2X2ltNuu67bnlpeXQ3ZbjU9PT799Lunz5GYff/vO5KNEcUIjmwjJJkKyicjZ3Lj7aaa5ublI+7u4uIC8t7f37W2/6meLWrM1Ny68I9lESDYR3ubG3V7tsLh9Y1VVVd7OxWefeBg0somQbCIkm4ic1ezt7W3I6Z83Mvt43+3z1Vhf7cudt394eMjYsbOJRjYRkk2EZBMRm77xiYkJyOPj44H/3ucrqN3PK7a0tPz42JlGc+PCzCSbCskmIjafepqZmYF8cHAA2X3+yu1ZyyZuD/vx8XHOjp1JNLKJkGwiYnPrFZbe3l7Io6OjkN124SDcr/UsLCxAdi/bcb6M69ZLmJlkUyHZRPzami3+jWq2MDPJpkKyiZBsIiSbCMkmQrKJkGwiJJsIySZCsokInBsX/xca2URINhGSTYRkEyHZREg2EX8BwO1Lk/OSqcsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    data_point = mnist_test_dataset[np.random.randint(len(mnist_test_dataset))]\n",
    "    output = plot_datapoint(data_point)\n",
    "    plt.show()\n",
    "    print(f'Prediction: {infer_model.infer_apply(data_point).item()}')\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824086b",
   "metadata": {},
   "source": [
    "## Reloading Pytorch Lightning Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11329348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading torch module from test/lightning_logs/version_12/checkpoints/epoch=0-step=49.padl/8.pt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'padl_model' and 'train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y4/wncq_2vx5_j42jklvxtlyjyw0000gn/T/ipykernel_33880/1079429527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test/lightning_logs/version_12/checkpoints/epoch=0-step=49'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_padl_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.padl/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpl_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadl_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaded_padl_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Aleph-One-Gmbh/padl-extensions/venv/lib/python3.8/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHECKPOINT_HYPER_PARAMS_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Aleph-One-Gmbh/padl-extensions/venv/lib/python3.8/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36m_load_model_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0m_cls_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_cls_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls_init_args_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_cls_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# give model a chance to load something\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'padl_model' and 'train_data'"
     ]
    }
   ],
   "source": [
    "path = 'test/lightning_logs/version_12/checkpoints/epoch=0-step=49'\n",
    "loaded_padl_model = load(path + '.padl/')\n",
    "pl_module = MyModule.load_from_checkpoint(path + '.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
