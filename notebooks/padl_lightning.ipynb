{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5492e1e4",
   "metadata": {},
   "source": [
    "## Install `PADL-Extensions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install padl-extensions[pytorch_lightning]\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9edcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These might be useful if there are errors regarding ipywidgets while downloading torchvision.datasets\n",
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8d957",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "import padl\n",
    "from padl import transform\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd944ba",
   "metadata": {},
   "source": [
    "## Using PADL with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de455b",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "MNIST dataset available through torchvision is used in this notebook. The dataset can be separately downloaded from MNIST website or can be loaded as given below. \n",
    "\n",
    "More details on torchvision's MNIST dataset can be found here: https://pytorch.org/vision/stable/datasets.html#mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "mnist_test_dataset = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a4df6",
   "metadata": {},
   "source": [
    "## 1. Model Definition\n",
    "\n",
    "We will build a simple `Unet` to classify `MNIST` handwritings. In the cell below, a simple `torch.nn.Module` is defined with the decorator `@transform`. This is enough to wrap the pytorch model into a `padl.Transform` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision.models.resnet \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv 1\n",
    "        # size : input: 28x28x1 -> output : 26 x 26 x 32\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 2\n",
    "        # size : input: 26x26x32 -> output : 24 x 24 x 32\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 3\n",
    "        # size : input: 24x24x32 -> output : 12 x 12 x 32\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv 4\n",
    "        # size : input : 12 x 12 x 32 -> output : 8 x 8 x 64\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # Conv 5\n",
    "        # size : input: 8x8x64 -> output : 4 x 4 x 64 -> Linearize = 1024\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # dropout layer \n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "\n",
    "        # FC 1 \n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "\n",
    "        # FC 2\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform\n",
    "def convert_to_tensor(img):\n",
    "    arr = np.asarray(img)\n",
    "    return torch.tensor(arr).type(torch.FloatTensor)\n",
    "\n",
    "preprocess = (\n",
    "    convert_to_tensor / convert_to_tensor\n",
    "    >> padl.same.reshape(-1, 28, 28) / padl.Identity()\n",
    ")\n",
    "\n",
    "simplenet = SimpleNet()\n",
    "loss_func = transform(F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a29794",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device to be used: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea65efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = (\n",
    "    preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> transform(F.nll_loss)\n",
    ")\n",
    "\n",
    "train_model.pd_to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_preprocess =(\n",
    "    padl.same[0]\n",
    "    >> convert_to_tensor\n",
    ")\n",
    "infer_model = (\n",
    "    infer_preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> padl.same.unsqueeze(1) \n",
    "    >> simplenet\n",
    "    >> padl.transform(lambda x: x.max(1).indices)\n",
    ")\n",
    "infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404e855",
   "metadata": {},
   "source": [
    "## 2. Converting a PADL model into a Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl_ext.pytorch_lightning import DefaultPadlLightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343acf6",
   "metadata": {},
   "source": [
    "## 2.1 Use the DefaultPadlLightning class\n",
    "If your `train_model` has the loss function as the final step you can initialize the `DefaultPadlLightning` object by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35407731",
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultPadlLightning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "padl_lightning_module = DefaultPadlLightning(\n",
    "    train_model,  # train_model with the loss function\n",
    "    learning_rate=1e-3,\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "# pad_lightning is a LightningModule !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3700cd82",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8dce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "nepoch = 1\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1 if device == 'cuda' else 0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=nepoch,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=log_interval\n",
    ")\n",
    "trainer.fit(padl_lightning_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de0b17",
   "metadata": {},
   "source": [
    "## 2.2 Inherit from BasePadlLightning\n",
    "The class `BasePadlLightning` is already a `LightningModule` so inherting from it allows for all the regular customizations available in Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl_ext.pytorch_lightning import BasePadlLightning, OnCheckpointSavePadl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "BasePadlLightning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(BasePadlLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "padl_lightning_module = MyModule(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_data=mnist_train_dataset,  # list of training data points\n",
    "    val_data=mnist_test_dataset,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "# pad_lightning is a LightningModule !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cca3e6",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aaeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "nepoch = 1\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"val_loss\", every_n_epochs=1, save_top_k=1)\n",
    "callbacks = [early_stop, model_checkpoint, OnCheckpointSavePadl()]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    gpus=1 if device == 'cuda' else 0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=nepoch,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=log_interval\n",
    ")\n",
    "trainer.fit(padl_lightning_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af13ee",
   "metadata": {},
   "source": [
    "## 4. Infer a few images from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform\n",
    "def plot_image(img_tensor):\n",
    "    fig= plt.figure(figsize=(2,2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img_tensor, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    return fig\n",
    "\n",
    "@transform\n",
    "def img_to_array(img):\n",
    "    return np.asarray(img)\n",
    "\n",
    "convert_plot = (\n",
    "    img_to_array\n",
    "    >> plot_image\n",
    ")\n",
    "\n",
    "plot_datapoint = (convert_plot - 'image')/ (padl.Identity() - 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    data_point = mnist_test_dataset[np.random.randint(len(mnist_test_dataset))]\n",
    "    output = plot_datapoint(data_point)\n",
    "    plt.show()\n",
    "    print(f'Prediction: {infer_model.infer_apply(data_point).item()}')\n",
    "    print('-'*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
