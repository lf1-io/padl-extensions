{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install padl-extensions[pytorch_lightning]\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd8aca",
   "metadata": {},
   "source": [
    "Imports for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f539bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test/lightning_logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a58dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import padl\n",
    "from padl import transform\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from padl_ext.pytorch_lightning.prepare import LightningModule as PadlLightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae64878",
   "metadata": {},
   "source": [
    "MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "val_data = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e0237",
   "metadata": {},
   "source": [
    "Simple convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33946dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339d9ed",
   "metadata": {},
   "source": [
    "Using a simple convolution net on greyscale images, we can define our pipelines with PADL's functional model builder. `>>` means to compose components (\"transforms\" and \"pipelines\"), `/` means to apply components in parallel. See more [here](https://medium.com/padl-developer-blog/padl-is-the-next-ml-ops-tool-you-should-learn-3e4ba6c66e6e).\n",
    "\n",
    "The output of the train-pipeline is a scalar loss. This differs from how you might normally write your training. Usually in PyTorch you would write a dataset, then wrap it in a dataloader, then define a layer and loss. In the training loop you'd fetch batches from the dataloader, push them through the model, and then evaluate the loss on the outputs. In PADL this logic is handled inside the pipeline. That makes it super easy to define very useful objects for talking to the PyTorch ecosystem, as we do here with PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"train_model\":\n",
       "\n",
       "   \u001b[32m   │└─────────────────────┐\n",
       "      │                      │\n",
       "      ▼ args                 ▼ args\u001b[0m\n",
       "   \u001b[1m0: \u001b[0m\u001b[32m[\u001b[0mpreprocess: ..\u001b[32m>>\u001b[0m..\u001b[32m]\u001b[0m \u001b[32m/\u001b[0m Identity()       \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mBatchify(dim=0)     \n",
       "   \u001b[32m   │└─────────────────────┐\n",
       "      │                      │\n",
       "      ▼ x                    ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mSimpleNet()          \u001b[32m/\u001b[0m type(torch.int64)\n",
       "   \u001b[32m   │\n",
       "      ▼ (input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mcross_entropy       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = (\n",
    "    padl.transform(lambda x: np.array(x))\n",
    "    >> padl.transform(lambda x: torch.from_numpy(x).type(torch.float))\n",
    "    >> padl.same.reshape(-1, 28, 28)\n",
    ")\n",
    "\n",
    "train_model = (\n",
    "    preprocess / padl.identity\n",
    "    >> padl.batch\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> padl.transform(F.cross_entropy)\n",
    ")\n",
    "\n",
    "train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507220b",
   "metadata": {},
   "source": [
    "Let's test the pipeline on a single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e421f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "namedtuple(simplenet=tensor([[ 0.1650, -0.4476, -0.1595,  0.1079, -0.5692,  0.0876,  0.0340, -0.2768,\n",
       "          0.5267,  0.1525]]), out_1=tensor([5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model[:-1].infer_apply(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb998a",
   "metadata": {},
   "source": [
    "We can define an auxiliary model with weights tied to `train_model` simply by reusing the layer. This model is useful in practice, since it outputs predictions as raw floats. This can then be plugged straight into the server or wherever. We could have also created a JSON output or whatever we liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f608f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"infer_model\":\n",
       "\n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m0: \u001b[0mlambda x: np.array(x)                          \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mlambda x: torch.from_numpy(x).type(torch.float)\n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mreshape(-1, 28, 28)                            \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mBatchify(dim=0)                                \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m4: \u001b[0mSimpleNet()                                    \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m5: \u001b[0mUnbatchify(dim=0, cpu=True)                    \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m6: \u001b[0mlambda x: x.topk(1)[1].item()                  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_model = (\n",
    "    preprocess\n",
    "    >> padl.batch\n",
    "    >> simplenet\n",
    "    >> padl.unbatch\n",
    "    >> padl.transform(lambda x: x.topk(1)[1].item())\n",
    ")\n",
    "infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ebd31b",
   "metadata": {},
   "source": [
    "The PADL extensions package contains a PyTorch Lightning plugin. This is a very lightweight extension of the PyTorch Lightning module. In the usual way with PyTorch Lightning, we can extend functionality by overwriting the default methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(PadlLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d82ce3",
   "metadata": {},
   "source": [
    "The difference with a standard PyTorch Lightning case however, is that the amount that needs to be defined is drastically reduced. Due to the structure of the pipeline, methods usually defined manually may be determined automatically. If you prefer to save the inference model rather than the training model, then this may also be passed to the Module. That means that the training model will be used to compute losses, and the inference model's weights will track those weights, and be saved whenever PyTorch Lightning monitoring determines that a good model has been found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb3f1f50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"val_loss\", every_n_epochs=1, save_top_k=1)\n",
    "callbacks = [early_stop, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    gpus=0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=10,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "\n",
    "padl_lightning_module = MyModule(\n",
    "    train_model,\n",
    "    trainer=trainer,\n",
    "    batch_size=256,\n",
    "    num_workers=0,\n",
    "    inference_model=infer_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031615c",
   "metadata": {},
   "source": [
    "All of the standard PyTorch Lightning functionality may be used with a standard PyTorch Lightning trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449dbf13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | simplenet | SimpleNet | 214 K \n",
      "----------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af1bd585d17473dac524735739bc26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "padl_lightning_module.fit(train_data=train_data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f74a38",
   "metadata": {},
   "source": [
    "Let's try a few predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35233d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAtUlEQVR4nGNgGORAMe/RBXYcchzr/734J4ZD0vDfDsHvodjlxG895g78i0NnzUdjxk0/RbBrfDOLgePfVU6skpHv5Rhm/8PuIL3vOxi0//3LZsQmGfvPlePMv+vYvbnxNEv8v9fc2N164cvl799Mscsx2L3+96cOhxwD05x/e3DJMaT+e8CPS8701z8XXHKSV/5tY8YhxzL73xlRXBod/l3HCHAmGMOQYdUbXBoZCqfjlKI2AACtrT2Z4Ie3JwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165160E20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAUlEQVR4nNXQoUtDURTH8d825cEURJld5zP7J6ggGAyCYrGIuGoQtmIQETSs2IYgCKILFg02sQyTGHRjiKyOPQRBmCAynt+LwbDdt6tg9KTL/dzz454j/duaOcSY8rY3+7EVpcH9EAAumpxEbK4CcHtdA8jbNl2F+q7vaRwwU5alAij6koZugEbKwhwEA5JixxBuDtupp8Dd2dJYAYKN6FczzwC8h7xku2f0j+6/B8l3m6REzyLwNtq+ibePmHlJijk7tR6N7egc2ZNC63UHriZVvHJnaiLgwWthll14Tim99sllv8P6nngstGDB1bjy2womAcxO3Im9B/Ca+2EDf64vRxiFrK1E4XgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7A60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/ElEQVR4nGNgoDnQff3fBJfcnF9/b8rgknzy94YCLrlpv6/jlGN4/VcXXYgFxkgSWHWdgUHKiWHfM0xJPqaTfzzLlaQZnn59M+nMfVQjbv+V9Pn+FwquoNoe//tvz92/h/yMjY2Nu5787UGRLPv79+/f50oQjv3fn6EMDAwMTMjujbgHteIVizmazpcNcJ793w8ormVgiNgPZ96BUEjG3kAwRTAkEYC1imENMl/3298SQRhH/+9HLRTVS/7+vZHNwsDAwMCicePvHAYGBgYGRpikYVEQB8OyNwwM+8Ki3jXvv4xmk+7in5DAe5qGzSFai//+/fuoWhOb3KAAAIarZayCHEfuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7F10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9klEQVR4nMXRsUtCURTH8R/5mqKwJSJBWsItXEJwigdCOARt1tzU7BTttoQt7ob/Q1Ag5ODmKggNBZGTLzF4ksP32XDr9ereOc90OR9+99zDlRZcq5eP0TwqOc1rAXARN5YSmDmRJG3lHcHsAFPPtm33Ae7GcGvn+sBoPzeEMwvLwPueDoGWhW1gKB0nZ3rfh0BSKr1RlzSykgcA903g6cjC9dPwa5OKY01dzQwuu1A1g0WXVacGw6pt/gRodGcw8f/a2gDoZVQeQ7BrevGvFHek8Drnf0RSetP0vGR65eb3bXHy5e2nGbxaQ8875rUPtYJrmX+qT6skh0TC+zVkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABD0lEQVR4nNWRv0oDYRDE5xNBCLExlaIoGK8SRK3ESsEXEAsLQRsfIArpBEF8BsFORLDUWrC6oES0TiV6BIKxOU1A0JnvLO5y5P7Ugtvt/tjZ2V3gP4VJZFOdseJdLiytzm9/jhbrAaq1pIJT8VqkSIq8TXRunQEDFjABYAJ0JzdnsN+DjXIIfh4BE8y2TBkY7IlGctcLALDuU3ypxhMfQtjcc4CrDqmTUp+f3XdZSVYXH1bSuZNwO34cSVN828mcY+3SjWB7Oedac37U7S9m2NCprNT0upKXgUek6E4v3ZD3aVaokWL7WSQraXgYuyWH03BCCnf9ej3IjCy4pMj6xkpc6vunMwIAT985S/5h/AIk46QCrNLmNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7C70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABF0lEQVR4nM3Pr0sDARjG8WfbbccMcqggGmwrgoaB9iEMTYrFtqDgDyxqm4LOIAxhVRAMNu0DDRYZM4h/wskMCuIsirtN0O8weCe7O7P4pPflw/PCK/2LJNbL7fZ05BfpShfrAK14iOLpe6D5gZMJWU8ReNrOv75NhGpjNeCyVzkmQ5YFGpt90sxqMogb4JxlJKUOTlIBG67hLEuSZcPtvM+673CWJGn8pn7VoiRJin6bsTWk6qEkxRpzsy/+o6NQ7feWHG7TTREWvHnwGkY6LPGI8/P3BRSMDjThwevtNLEt+fHcHfNg+980YUWSNFBpBU0mHEma2nuGgqUQfh6vVd6BXSNgipRwk40FTUruA5wuxqNh+9t8AUaQg8Y7C08iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7AF0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAy0lEQVR4nM3QvWrCUBjG8QcVMmqHQgvqICWDWxdLl+4OOuju6KJjb8RBehkZdPASLN0LmRQkSuzkFAL5Ewe/qDkRcfKZDvzOA+/7Sneeh8/45zXFCkOgbbb8FPBzZnQAfCNlv0KAkRH7APBuso8QAuDZYC8z8Hr/MHN4NCZlLeu2FCd79hwW0gAcJZpOSfqVjPu3AAhDIOqe41vAMacj7E/1XelYtar1JGmdaO6Sd2H1mBxIkrTZSMFfCkqSpws4voTpaUZu8frft2YLnuhe0kKC2dkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7D30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA50lEQVR4nGNgGGSAEUonzzl1NmwVg/bVY5efv0JX1PMXDo5j6GRTc4MwOpn+e+3CYU3On7/PhLHKCJW8+vn3lQdWuaLHf/8+rMKijzl27f1ff38XYjUy4O/fv3///lkWYopFUnTTjx+///79+/f7RjMmdK8wMDAw6BsziAWaMDDMyv+Fwy95e//+nYJDjoGByfPT3zw2nNK+X/+q4JTkevG3FWIIFslUUYbnOPRxNH/7e0UIq5R0w4m/f69Io4mqHQ/l5ub2vvz3758VsuhaQqBR/WVBEKZ5Ar33/v79+2KqBk5PUA0AAKiqZgmxl2E6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7E50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5klEQVR4nGNgGDaAEUpHybBbuTIxMDD+3+v9C1VJ1Kuff+FgMy9MmImBgYGBgV2YBaHSa4EgiiQDA8PPkyd7HfYxMDAwMAQ4oxib+PfvbQYGBvl4iMEPNSHCcONEpjMwxHAxMDAwMPzpuo6mEwFOBKM6CAWcW4sqee8ThPdi+UNkZRA7D1qqZjOo3Ds3++5SeQYZzu+YxikzMTAw6K79+9cGUw4KJvz9uwqng/4wMDBjcSUEsP/9+9cMl04GBgYGC1w6GXv+/v2ah0tW+vPfv1dwGft0DpyJxc6b+CRPLGbYistOJAAAyP1Vshm1kIUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoElEQVR4nM3RIQ/CMBAF4GuCGnb8iFo8FtDVaDwaB9Vo/CwJEo2e3fQSXBPcBObegQC19KEQnGrypffyciJ/P5UhMPM9tCvf79EQj4UTRz6GhULrvMXWYDjkcTWFovlEDjNvDyfufCeZF+ipyNMkwhJruYZiTmwDw5ZYuCoaYuPWUJcEo0JnbKnB9sR8zxvKEpY8W5p4Q6meX++/Y/bzeQGqd0e8qGAExQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1643A7F40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    image, label = val_data[random.randrange(len(val_data))]\n",
    "    display(image)\n",
    "    print(padl_lightning_module.inference_model.infer_apply(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854c58f",
   "metadata": {},
   "source": [
    "The following cell works in a completely new session. You can restart the kernel, do this in a new session/ server etc..\n",
    "That makes the results which you obtained with the PyTorch lightning trainer super portable and reusable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d3e56e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "m = padl.load(padl_lightning_module.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a054d",
   "metadata": {},
   "source": [
    "Let's verify the predictions of the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ebecbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEUlEQVR4nMXRMUtCURjG8VclFBqCQMKucCczXJKGcCqiFqEv0FBEVEOfoaXN2aUIl2gIEcoIkvDODTYF9QEKtCRQArG86v823LrgOXeuZ3o4Px544Yj8b0LpjaP3VnXBz7ZqAPB1kNZse8BvDlWLfwDcl05WHniKK3gNFBMRERm/YlNBC6djuDXzWXVL8McmTXH6dbebdm90mADabp1r9JZGMfoC3VkRCaTq5NVrLaAxLdES3M6rOHMHnO/UYH9CNZHQsg3wmg14T0GvDY2hiEir4ujD3TcbgMFpREcL7PJ6rg0XUz74nBSRvS5k/ZY3+VXDuISzsIoVAJpNoB9T0Tz2vrOsXzS2VgAeobCo49/lGxyxmT8NIhITAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165980670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABH0lEQVR4nM3Nvy9DURjG8e8VIu2EtCVsbFJiaAwlTBK6ielukhpMDP4Am8HS0dDEQMIg0T/ALg2pkkhopCQisWiJ1E1InnsNt1fuD6PBs5xz3s9588D/zvD6i2Pfjv5GyX1HkvQxGLXFB9k62pOUj9jml+TcJY2lQ1XClmhIsk8AU1fuqMOzqeOe++wzNQBGMoG9nCWtUlcOMHUT81vfmVSC+haAKWvSjyvSYxqyuFgKdZK/hlMAJnhyR53uYRi8/3yb9TbaOOT4Ohz70l+Zt1SNe4/xVqvX39nsZsfycCNmv/pxHpY96xogmHRZtWz7viYVg5ppqToHQHxbF8nQ7kxTn8WFseliQ+UU4RxIkmzpvD9ipHYrkt4KhUTU/jjfEQt1DxMx/RcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAf0lEQVR4nL2RwQ3DMAwDr0D3MjNZ1ckkT6Y8jARIbOUZfgSDJkGJ8D4+16fRBNFt+mieB3xSuoDo0MQWk1RjKnP2PS0yVXFZc/Ijz5qrdFZ7yjO94CzrHfwhZtaWWL3B41WW3GhFPxGdJv5ELHLeugT4wllV9DFutq7oWJXnVezkQlgHCWk/qAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E5E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4nGNgGNTAe/bhbOwyLEGX/v368msGNjmlFf/+rTZlmLYDi5zO3n9PrBgZGEq+emLIsR3/d0SFgYGBIexfI4ObIapk9b/HOgwMDAwMTMvUTb8uQZW8868WyhLh2PIvBsJkglDcbAwfoJJvBNzeHkTR6PTvkQCMnf6vD9XUJf82w5haH/+JokqG/LvEBWFx7vr3TwTNK3f+RTAwMDAw8O/+hym58t99bUYGZsvdn1ZjSrKv+/dv/ard/y7ZuWNKMnDGPv3771IDN4P7v+tc6JIMDAzu3kwMDAxp/9bBBFiQJHcyMDAwMAcgBJjQtfN64JFEBhiS/gwMm/BpoAIAAGR7VA3cZU2oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6klEQVR4nGNgGLRg6t+/fxO4sctN/vvnz58/e7HKSb35++fPnz/fk7HIWT748/f1ggWn/n6xwJSs+vPnsw0Dg/3fP5VIokwQyp6RcesRBmFHJkZXVgydi/8812JgOP/n758/zhiSxtsNGKCSj5uxe+f8n79//vz5g24nBCz69q13DQPDJexaGRgYGDo+/o/BLRv/txC3JMPf28K4JS//ccVwkJgClPEGi4ZF9xIlGBgYOBv+/62CiDAiJCOWMDAs+8+gaMX43eUEuk79P38ggfA9CdNYTt21EMlJWJ3J6X3yz93OTtz+oA4AAHm+ZTNY81xDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABB0lEQVR4nGNgGCyAtfDdf3QxlhgZBgYGZaNZm//+/cvAwMCCLJk65e1BBoZARgYGhtcr0TQyrf0LBaf61dFNNYDI/FzSx4vpjHV//06XlZWVweJC5ht//15nZWXE5nr2+X///v27/smCKB5MSasXMNec7UWXU3v19+/fvzcOHTr04++XKCySVdZiDAwMWX/+nkPXKt+ZxwRhHfz7RBFZxnaFKoKDLtn79wQznPMTbizEKDkG0y42bB5kYGBgEPr7968rlD39z49CFEnW6X//PvVnZmBgEHF6+/cBmlaOPX///j29LyT/5t+/PxPQDZaYDgugv7GY1rJat//4+/fv379xWIOebgAA43V/8s3WacMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nM2RSw7DMAhEn6vcK+RkISczORld+B/aZaXOzvPMgAD+TGl5icAJh4V/6l3yZLkCdXct1jYigcsMOGN3VW0J+nEgwCdzm4HIvhQMqLHX1mvC+KPMJ+XmvuYvV0rpAGnT1lgDimXXaN2gdWcfSUtsk0WYS+5dNrkql62puwcm7gKq7rkXzuvLhgC3EaTfDt1pPdtv9QbtGlXun99R5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDUlEQVR4nNWQrUtDYRjFz9X5VYQbNoYgrOmCRdEqGMRkEV0Qs6BBm952wWIaJqv4B/hRLIKIZTDEpNYJd47BDIIizsvvRcPlsrsrbzJ5yvtwfpznPTzSnzXhBaac8nriYSh/Vi+N2cOXrFmSUi77HliD6zxYmXv/C3bWLhftbfQIvjUpmdvoHYyNTDxMZnV3IUl+3+xN47B7xbMx+9K8922MMelbBTDnXn9i4PiE8CANV66Ao8JIZmDm6WU8wVbb0IRKdF23wkYCbgLwsShJmj6nmUu0bYX9kuRIU73bC8OqtVJ/Av7WaRuoeaNdhZbqAGCgsZtXSntvEXzdcWPL6dBCKVv8qjrlMB37J/oBxvp2k/vLaMoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E7F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEElEQVR4nN2PwSpEARSGf5eZQY1GTZqaMkZN2cgTULLxAqas2EyKtaymUB5gZmEjk70XMEVZadwViUkoMTY3xMKd7p3pY3HLcO/d2vg3p9N3/nP+I/0bdXklZkhS+qnV9kNjIbOc9Nrru5fbhmr1zkAFAAfbxpM164EeSa5qm4OWNXTPqKbmUgkllw6+ncZkZ0t0rQHNSli8sY1zeDTHgySdP7WhWYz4X5HipXy/JO1rwDHNo89fvvgDP7Tj27r1AdSdq8PiDeC/OZzL5aLZyMxFG17D4k6sV1tgllMB0lfYdeGtPG/4SaxQtYD3UtpPVrYvnwFOVgNIIy7AXjbRHRKj94zjxUwYkaTpfCDDH+oLjxh9QwqYW18AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAyklEQVR4nGNgGMJg+Yt8YVxyod/+/VvFhEPy+r9/T//NxyrF0vbv32zp6x9VsMhJ9f/7d1eOofefNxZ9E/79+2nKwOD+rw5TMuPfv3+rGRgY3P+95EOXs3r37997TgYGBvd//0TQ5DjO/vv3QI2BgYFB8AWG5KZ///4lQpgP4ZIsUFqLgYFhWg7Dhrdqt3gwnHP0HxKA6WSE0sJRclCWsz6j2BtMzzDA7AyHsrCGsiJuyZ0MbrglnzDI4jOWAZ/kVtzq9bdjBgOpAABa50y6UlwmqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x16440E670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    image, label = val_data[random.randrange(len(val_data))]\n",
    "    display(image)\n",
    "    print(m.inference_model.infer_apply(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31858c",
   "metadata": {},
   "source": [
    "Continuing training is a simple as pie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ea83eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at test/lightning_logs/version_0/checkpoints/epoch=0-step=119.ckpt\n",
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:250: UserWarning: You're resuming from a checkpoint that ended mid-epoch. Training will start from the beginning of the next epoch. This can cause unreliable results if further training is done, consider using an end of epoch checkpoint.\n",
      "  rank_zero_warn(\n",
      "Restored all states from the checkpoint file at test/lightning_logs/version_0/checkpoints/epoch=0-step=119.ckpt\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | simplenet | SimpleNet | 214 K \n",
      "----------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e0845b966f4061a0543e969f65dae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "m.fit(train_data=train_data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de3bc0",
   "metadata": {},
   "source": [
    "And that's all there is to it. Nice pipeline definitions in PADL trained at warp speed with PyTorch Lightning.\n",
    "\n",
    "**Happy PADL-ling!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
