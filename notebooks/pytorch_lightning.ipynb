{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install padl-extensions[pytorch_lightning]\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd8aca",
   "metadata": {},
   "source": [
    "Imports for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d969c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install huggingface transformers dependencies (pip install padl-extensions[huggingface]) to use connector\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import padl\n",
    "from padl import transform\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from padl_ext.pytorch_lightning.prepare import LightningModule as PadlLightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae64878",
   "metadata": {},
   "source": [
    "MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "valid_data = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e0237",
   "metadata": {},
   "source": [
    "Simple convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33946dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339d9ed",
   "metadata": {},
   "source": [
    "Using a simple convolution net on greyscale images, we can define our pipelines with PADL's functional model builder. `>>` means to compose components (\"transforms\" and \"pipelines\"), `/` means to apply components in parallel. See more [here](https://medium.com/padl-developer-blog/padl-is-the-next-ml-ops-tool-you-should-learn-3e4ba6c66e6e).\n",
    "\n",
    "The output of the train-pipeline is a scalar loss. This differs from how you might normally write your training. Usually in PyTorch you would write a dataset, then wrap it in a dataloader, then define a layer and loss. In the training loop you'd fetch batches from the dataloader, push them through the model, and then evaluate the loss on the outputs. In PADL this logic is handled inside the pipeline. That makes it super easy to define very useful objects for talking to the PyTorch ecosystem, as we do here with PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"train_model\":\n",
       "\n",
       "   \u001b[32m   │└─────────────────────┐\n",
       "      │                      │\n",
       "      ▼ args                 ▼ args\u001b[0m\n",
       "   \u001b[1m0: \u001b[0m\u001b[32m[\u001b[0mpreprocess: ..\u001b[32m>>\u001b[0m..\u001b[32m]\u001b[0m \u001b[32m/\u001b[0m Identity()       \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mBatchify(dim=0)     \n",
       "   \u001b[32m   │└─────────────────────┐\n",
       "      │                      │\n",
       "      ▼ x                    ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mSimpleNet()          \u001b[32m/\u001b[0m type(torch.int64)\n",
       "   \u001b[32m   │\n",
       "      ▼ (input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mcross_entropy       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = (\n",
    "    padl.transform(lambda x: np.array(x))\n",
    "    >> padl.transform(lambda x: torch.from_numpy(x).type(torch.float))\n",
    "    >> padl.same.reshape(-1, 28, 28)\n",
    ")\n",
    "\n",
    "train_model = (\n",
    "    preprocess / padl.identity\n",
    "    >> padl.batch\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> padl.transform(F.cross_entropy)\n",
    ")\n",
    "\n",
    "train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507220b",
   "metadata": {},
   "source": [
    "Let's test the pipeline on a single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e421f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "namedtuple(simplenet=tensor([[ 0.1034,  0.1571, -0.0197, -0.1410,  0.1025, -0.0769, -0.0533,  0.4350,\n",
       "          0.2423,  0.6320]]), out_1=tensor([5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model[:-1].infer_apply(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb998a",
   "metadata": {},
   "source": [
    "We can define an auxiliary model with weights tied to `train_model` simply by reusing the layer. This model is useful in practice, since it outputs predictions as raw floats. This can then be plugged straight into the server or wherever. We could have also created a JSON output or whatever we liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f608f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"infer_model\":\n",
       "\n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m0: \u001b[0mlambda x: np.array(x)                          \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mlambda x: torch.from_numpy(x).type(torch.float)\n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mreshape(-1, 28, 28)                            \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mBatchify(dim=0)                                \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m4: \u001b[0mSimpleNet()                                    \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m5: \u001b[0mUnbatchify(dim=0, cpu=True)                    \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m6: \u001b[0mlambda x: x.topk(1)[1].item()                  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_model = (\n",
    "    preprocess\n",
    "    >> padl.batch\n",
    "    >> simplenet\n",
    "    >> padl.unbatch\n",
    "    >> padl.transform(lambda x: x.topk(1)[1].item())\n",
    ")\n",
    "infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ebd31b",
   "metadata": {},
   "source": [
    "The PADL extensions package contains a PyTorch Lightning plugin. This is a very lightweight extension of the PyTorch Lightning module. In the usual way wiith PyTorch Lightning, we can extend functionality by overwriting the default methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(PadlLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d82ce3",
   "metadata": {},
   "source": [
    "The difference with a standard PyTorch Lightning case however, is that the amount that needs to be defined is drastically reduced. Due to the structure of the pipeline, methods usually defined manually may be determined automatically. If you prefer to save the inference model rather than the training model, then this may also be passed to the Module. That means that the training model will be used to compute losses, and the inference model's weights will track those weights, and be saved whenever PyTorch Lightning monitoring determines that a good model has been found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3f1f50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "padl_lightning_module = MyModule(\n",
    "    train_model,\n",
    "    train_data=train_data,\n",
    "    val_data=valid_data,\n",
    "    batch_size=256,\n",
    "    num_workers=0,\n",
    "    inference_model=infer_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333b36c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lightning_optimizers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpadl_lightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:155\u001b[0m, in \u001b[0;36mLightningModule.optimizers\u001b[0;34m(self, use_pl_optimizer)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the optimizer(s) that are being used during training. Useful for manual optimization.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    A single optimizer, or a list of optimizers in case multiple ones are present.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pl_optimizer:\n\u001b[0;32m--> 155\u001b[0m     opts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_optimizers\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     opts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizers\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lightning_optimizers'"
     ]
    }
   ],
   "source": [
    "padl_lightning_module.optimizers().state_dict()['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031615c",
   "metadata": {},
   "source": [
    "All of the standard PyTorch Lightning functionality may be used with a standard PyTorch Lightning trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d080afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"val_loss\", every_n_epochs=1, save_top_k=1)\n",
    "callbacks = [early_stop, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    gpus=0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=1,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b8638",
   "metadata": {},
   "source": [
    "Now let's do a lightning training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1631377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | simplenet | SimpleNet | 214 K \n",
      "----------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4768f0973de641eb89236dcab6f47b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=9.padl/9.pt\n",
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=9.infer.padl/5.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=19.padl/9.pt\n",
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=19.infer.padl/5.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=29.padl/9.pt\n",
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=29.infer.padl/5.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=39.padl/9.pt\n",
      "saving torch module to test/lightning_logs/version_1/checkpoints/epoch=0-step=39.infer.padl/5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/Attraqt/tenen/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(padl_lightning_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba4bf3",
   "metadata": {},
   "source": [
    "The following cell works in a completely new session. You can restart the kernel, do this in a new session/ server etc..\n",
    "That makes the results which you obtained with the PyTorch lightning trainer super portable and reusable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "010432be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading torch module from test/lightning_logs/version_1/checkpoints/epoch=0-step=39.infer.padl/5.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m:\n",
       "\n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m0: \u001b[0mlambda x: np.array(x)                          \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mlambda x: torch.from_numpy(x).type(torch.float)\n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mreshape(-1, 28, 28)                            \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mBatchify(dim=0)                                \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m4: \u001b[0mSimpleNet()                                    \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m5: \u001b[0mUnbatchify(dim=0, cpu=True)                    \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m6: \u001b[0mlambda x: x.topk(1)[1].item()                  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = padl.load(trainer.checkpoint_callback.best_model_path.replace('.ckpt', '.infer.padl'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f74a38",
   "metadata": {},
   "source": [
    "Let's try a few predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35233d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiklEQVR4nM2QuxXCQAwE9/Hoy0tliMrOVDYEOnzYJxMRoECBRp9dSf8dDrAUnlEAgAQhSdcPtGT/quiVDfpuSQ8p0bKHltbbtuY53esyDO2gE0gdHm0HilvvqZ3McxnfWAC0mjVgEjp2NgOjchlzuydM9+Kdi6WRXmvotHIm59Rkf09tJH9bzv06Xtm+d+pkTv/rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x164FC6370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5ElEQVR4nM2QIU8DQRCF3xFU9VUj4Wy3loa/0P0N5DS6trWQ4NBgm9r+AdwlqN71ZCV7tnbfDGZ7IZmVCGbETObLTN4b4P/GzaZr3STPfDgw8vBSZtg8CIVCaacWhsiUewuVsq2bU/NxlrWBjOsJyhJYMRo5wtQthHVqr1PdqVbH6RLon1XN2YHSJr000H1f1G5nVq4f0l5tGfAWGRnbnE9AKKECmi7zX88YZgDeOT7haoRlUTx8AfgsvIVI/u701p6tlJ2buw3V+gSeRqc5uX6gUnm6vwyK39Q9YtkfX/vc5h/GD6bgiiNcS4R+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE6370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/klEQVR4nMXQMUsDQRCG4Y9w4olwUdBKNKWNtT9BgyJobxksJQRESxVSCfbWBisLwUIU/AdamPLAIOKJpDkUxMjxrha5i+5e0upUHzwzu8NI/15zkTHN0gCMAFr7Xh+abZjPGKCat1qL2w2/Xg85ztlOAuOSdJ7hz+vedCE5jAfssgm73dSbLGRWPtDDidPfwxnvZS2UJAWBIrup/Mp2GpchsGz4zLwtpvnRGBuLUEljpcP9qPXniPSc4sTQ08q7NdmApW7yL7L0a9u05sOFdtvB7DKlrSld3jgDRTiStGrgOnBMY5DEcfzxxZXvmry9DgB3p5M5k7TeBOgnf1vfM5to8Jib8UwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE63A0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0ElEQVR4nGNgGEqAEc5yUoLQa99jqor8+efPnz9//v758umWL7rOW/8aWFWv6T+IY5CVam5E0ylbLAFl6f15KYjTGRv+XOLGIcXT/uO2Ay59U/78KcEl5/f5z2cj7FLcQf//PrJEE1RzdlZgYGCwOf7n70ZedB27/vy5k5KS+ebPn6P6SMKQQPj7H8aX//YetyTjiwPT/zAw3HuFUFL66M+fP9sdqpZ8/Pvnz58/f/7cPjYNrpOB39xqz8nfDAzCzL4KDAzh4gwMF+xx+XZIAgD23lKlu9PsxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE64C0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nMXPrUtDARQF8KOuKAyElxwPbEsranlgEBVNxllWxDAYCBaDUdzijEb3BwwX/CgG0WIyKCzoWxAcaHBJGUyEc/YMmyDcm/WmCz/uxwH+u1KlV+1PAGkPz0nqZrd+HzkoHkYrz6SuAmNFMQJy1YJoR0+Si0GTfM4abCsPAEFNx/bkEBu8s1vXvpQH0pe922GU0V84nhoBMteL8XLXIpIku9GaaVW6Tsp1iuSRjfiDDwWXJktn6r9MexRsxSTFsocN6q0cxexsW5vr8WMeCB/5bjHTVH8TwKq0YHXpSZ1Krd4ms87RqcFD3HOjhNVTHuyEYy7+XX0DAxBvlbT/KE0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE6580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5UlEQVR4nGNgGArgfxFOKe74Teq45CQv/X0tjUWcd5sZA0PT378NWORMr/61YjB9/fc6Frnef/92iPPt+vclGFNO79/v01wMvX//roALscBZQQwXTBkY+BmeN2NqNPnxxY+BQeDb3/lYbOz4e5iBgWHtv68GWCRf/7tozqD//H+HsLV1xQQ0yb1///269vrvv9ePPr3sMEKT1Nr27+/fv3///T2mjcVcDq36v3//NguzYZFjYGCw+vu3G7sMAwPfrn/nxXFJFvz9q4RLzuXf32M47GNgmPbvEzZ3QjS+/1eJS47KAAAF31in6EcpuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE6400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3UlEQVR4nNWRIQ/CMBSEbwSF3ixIOjuw7D8wXT0k/wEScARH0FjQWAiywcEmIcHQJSgSVF+HgJCtY5aEk9/18u71Af8k6zt2up14hGoWtVMregAOb/b0Jc69Dtek6CCEOJGSMztrcanpLMQ9IS3XoZuLBVJt+jbA6p5XNwo0pB66KNFKLWtF+m5rWwHGAPbfkvxKihSpfJXPJ/isw4BWehtNy2Z7Q1KLMhPglHxWqZgmS6PSYBDRxGR+6AJwJuJOA9s0OaXH+VaTprDgoTF77bn0sjRzbJ/tYjP0ez0BN/lZUr1n1XAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE64F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBUlEQVR4nGNgGJpApnv535/9+/f/32DChCF58Q8E7D79JwIqxIiQVO5dzcDAwHCF5yzva4bf0TcZGFgQWtnvXmFgYGAQ2q/EyLHw6V0UY0t+vcxhYGCQ3Pjnebc8hqVlf17GMThd+LvfBItzmZb++u51689Sduy+af7z5/0CXF4VP/0nDpccg9+bP4ftcchxzPtz5+tZWaxybLOfNjHs/nMHq6TTH08GBqcPP7KxyJl+/m7EwMAw8+8uLJIpf9YyMDAwMDxFSCLHzmoGBgYGhlUM2CTfbmFgYGDgMkWIIMWK8IZ7Z44rLuJYiMVOqY1//vz58+d2FlavMGf2Hf6zShGrHKkAAEWGYFeyErApAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE65B0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkUlEQVR4nM3S0QmCMQyF0Q9xjc4hXSR7GOcoOEcHySDRPa4PP4hC8irep8LpDYUU/iOmsIbGlqRRiYeUTtH0kHLPcuCSDvECMwfAiFVhAFhG9ZqlBa7SmJljKUsDVzY9wPRtp0+8wP3RFF2p3dhU2Dee36dx5fZserg2puiGHheqmDaz3iOYMpXdD9ipZpU/zQvU5U2qO7eq9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE65E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3klEQVR4nGNgGBQg5/n/ZAiLBV1KcIUj838V7No0L//9+3eiFlY50/d//57U5MAud/jf31msONwy/9/HPgYG8YoqLHIFv772MbDXPb2NzUHr/9YJ1xz/e0AOi5zw9xsiS/7+vSGNzUae+19u/vu7Uwm7ezb8+/d/Lw63un38+/cMG3Y54Ud///69yoNVTuDk37+bn/7LxirZ/u/vLFabfy+xydn9+z+dgUH8/ytskh1/H4kySK38twdJDCk+P1s5u6u8rcWms+rvv79//+40xeoeztZ/q2Y78mGVoycAAHHIWftPL+EUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x165BE6670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    image, label = valid_data[random.randrange(len(valid_data))]\n",
    "    display(image)\n",
    "    print(m.infer_apply(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb212d",
   "metadata": {},
   "source": [
    "And that's all there is to it. Nice pipeline definitions in PADL trained at warp speed with PyTorch Lightning.\n",
    "\n",
    "**Happy PADL-ling!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
