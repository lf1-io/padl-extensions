{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install padl-extensions[pytorch_lightning]\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd8aca",
   "metadata": {},
   "source": [
    "Imports for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d969c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import padl\n",
    "from padl import transform\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from padl_ext.pytorch_lightning.prepare import LightningModule as PadlLightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae64878",
   "metadata": {},
   "source": [
    "MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "valid_data = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e0237",
   "metadata": {},
   "source": [
    "Simple convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33946dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339d9ed",
   "metadata": {},
   "source": [
    "Using a simple convolution net on greyscale images, we can define our pipelines with PADL's functional model builder. `>>` means to compose components (\"transforms\" and \"pipelines\"), `/` means to apply components in parallel. See more [here](https://medium.com/padl-developer-blog/padl-is-the-next-ml-ops-tool-you-should-learn-3e4ba6c66e6e).\n",
    "\n",
    "The output of the train-pipeline is a scalar loss. This differs from how you might normally write your training. Usually in PyTorch you would write a dataset, then wrap it in a dataloader, then define a layer and loss. In the training loop you'd fetch batches from the dataloader, push them through the model, and then evaluate the loss on the outputs. In PADL this logic is handled inside the pipeline. That makes it super easy to define very useful objects for talking to the PyTorch ecosystem, as we do here with PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"train_model\":\n",
       "\n",
       "   \u001b[32m   │└─────────────────────┐\n",
       "      │                      │\n",
       "      ▼ args                 ▼ args\u001b[0m\n",
       "   \u001b[1m0: \u001b[0m\u001b[32m[\u001b[0mpreprocess: ..\u001b[32m>>\u001b[0m..\u001b[32m]\u001b[0m \u001b[32m/\u001b[0m Identity()       \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mBatchify(dim=0)     \n",
       "   \u001b[32m   │└─────────────────────┐\n",
       "      │                      │\n",
       "      ▼ x                    ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mSimpleNet()          \u001b[32m/\u001b[0m type(torch.int64)\n",
       "   \u001b[32m   │\n",
       "      ▼ (input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mcross_entropy       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = (\n",
    "    padl.transform(lambda x: np.array(x))\n",
    "    >> padl.transform(lambda x: torch.from_numpy(x).type(torch.float))\n",
    "    >> padl.same.reshape(-1, 28, 28)\n",
    ")\n",
    "\n",
    "train_model = (\n",
    "    preprocess / padl.identity\n",
    "    >> padl.batch\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> padl.transform(F.cross_entropy)\n",
    ")\n",
    "\n",
    "train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507220b",
   "metadata": {},
   "source": [
    "Let's test the pipeline on a single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e421f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "namedtuple(simplenet=tensor([[-0.0670, -0.1799, -0.0126, -0.1423, -0.5187,  0.3027,  0.2968, -0.2649,\n",
       "         -0.1286,  0.2499]]), out_1=tensor([5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model[:-1].infer_apply(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb998a",
   "metadata": {},
   "source": [
    "We can define an auxiliary model with weights tied to `train_model` simply by reusing the layer. This model is useful in practice, since it outputs predictions as raw floats. This can then be plugged straight into the server or wherever. We could have also created a JSON output or whatever we liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f608f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m - \"infer_model\":\n",
       "\n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m0: \u001b[0mlambda x: np.array(x)                          \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m1: \u001b[0mlambda x: torch.from_numpy(x).type(torch.float)\n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mreshape(-1, 28, 28)                            \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mBatchify(dim=0)                                \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m4: \u001b[0mSimpleNet()                                    \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m5: \u001b[0mUnbatchify(dim=0, cpu=True)                    \n",
       "   \u001b[32m   │\n",
       "      ▼ x\u001b[0m\n",
       "   \u001b[1m6: \u001b[0mlambda x: x.topk(1)[1].item()                  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_model = (\n",
    "    preprocess\n",
    "    >> padl.batch\n",
    "    >> simplenet\n",
    "    >> padl.unbatch\n",
    "    >> padl.transform(lambda x: x.topk(1)[1].item())\n",
    ")\n",
    "infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ebd31b",
   "metadata": {},
   "source": [
    "The PADL extensions package contains a PyTorch Lightning plugin. This is a very lightweight extension of the PyTorch Lightning module. In the usual way wiith PyTorch Lightning, we can extend functionality by overwriting the default methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(PadlLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d82ce3",
   "metadata": {},
   "source": [
    "The difference with a standard PyTorch Lightning case however, is that the amount that needs to be defined is drastically reduced. Due to the structure of the pipeline, methods usually defined manually may be determined automatically. If you prefer to save the inference model rather than the training model, then this may also be passed to the Module. That means that the training model will be used to compute losses, and the inference model's weights will track those weights, and be saved whenever PyTorch Lightning monitoring determines that a good model has been found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff882e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mMyModule(padl_model=[../..] >> Ba... cross_entropy, train_data=Dataset MNIST...  Split: Train, val_data=Dataset MNIST...   Split: Test, inference_model=<anonymous Fu...tionTransform>, batch_size=256, num_workers=0)\u001b[0m - \"padl_lightning_module\":\n",
       "\n",
       "   MyModule(\n",
       "     (simplenet): SimpleNet()\n",
       "   )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "isinstance(padl_lightning_module, pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb3f1f50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "padl_lightning_module = MyModule(\n",
    "    train_model,\n",
    "    train_data=train_data,\n",
    "    val_data=valid_data,\n",
    "    batch_size=256,\n",
    "    num_workers=0,\n",
    "    inference_model=infer_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031615c",
   "metadata": {},
   "source": [
    "All of the standard PyTorch Lightning functionality may be used with a standard PyTorch Lightning trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\")\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"val_loss\", every_n_epochs=1, save_top_k=1)\n",
    "callbacks = [early_stop, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    gpus=0,\n",
    "    val_check_interval=10,\n",
    "    max_epochs=1,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b8638",
   "metadata": {},
   "source": [
    "Now let's do a lightning training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(padl_lightning_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa338e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "padl_lightning_module.pd_save('test_pl_trainer', force_overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba4bf3",
   "metadata": {},
   "source": [
    "The following cell works in a completely new session. You can restart the kernel, do this in a new session/ server etc..\n",
    "That makes the results which you obtained with the PyTorch lightning trainer super portable and reusable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010432be",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = padl.load(trainer.checkpoint_callback.best_model_path.replace('.ckpt', '.infer.padl'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f74a38",
   "metadata": {},
   "source": [
    "Let's try a few predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35233d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    image, label = valid_data[random.randrange(len(valid_data))]\n",
    "    display(image)\n",
    "    print(m.infer_apply(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb212d",
   "metadata": {},
   "source": [
    "And that's all there is to it. Nice pipeline definitions in PADL trained at warp speed with PyTorch Lightning.\n",
    "\n",
    "**Happy PADL-ling!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
