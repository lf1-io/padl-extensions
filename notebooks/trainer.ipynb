{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install padl-extensions[trainer]\n",
    "!pip install padl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import padl\n",
    "from padl_ext.trainer.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5793e",
   "metadata": {},
   "source": [
    "This tutorial and accompanying notebook show you how to implement a highly portable training object for PyTorch modules using PADL. We'll be using the classic MNIST dataset and a standard CNN for illustrative purposes. The same approach applies to arbitrary PyTorch models. For more background on PADL see here and here, \n",
    "and a fully working example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ade97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "valid_data = torchvision.datasets.MNIST('data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69355079",
   "metadata": {},
   "source": [
    "Here's our layer transform implementing the CNN. Notice the decoration `@padl.transform` - all that's necessary to access\n",
    "the full range of cool PADL functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ef264",
   "metadata": {},
   "outputs": [],
   "source": [
    "@padl.transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fad549",
   "metadata": {},
   "source": [
    "All tensors in PADL are accessed by pushing data through \"pipelines\" or \"transforms\". \"Transforms\" are the basic\n",
    "building blocks and pipelines are compositions, and branches built up from \"transforms\". \n",
    "\n",
    "In the example below, `train_model` is built up of a preprocessor, which prepares tensors, and additionally\n",
    "a relatively trivial branch for the target labels. The prepared tensors are pushed through the layer, followed by the loss\n",
    "together with the labels.\n",
    "\n",
    "The pipeline makes use of the overloaded operators `>>` (compose) and `/` (apply-in-parallel). For more \n",
    "introduction to these operators see here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = (\n",
    "    padl.transform(lambda x: np.array(x).astype(np.float32))\n",
    "    >> padl.transform(lambda x: torch.from_numpy(x).type(torch.float))\n",
    "    >> padl.same.reshape(-1, 28, 28)\n",
    ")\n",
    "\n",
    "train_model = (\n",
    "    preprocess / padl.identity\n",
    "    >> padl.batch\n",
    "    >> simplenet / padl.same.type(torch.long)\n",
    "    >> padl.transform(F.cross_entropy)\n",
    ")\n",
    "\n",
    "train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c24f1",
   "metadata": {},
   "source": [
    "When we eventually use the trained layer, we won't need the loss or the labels. For that reason we create an\n",
    "additional pipeline, whose weights are tied to `train_model`, which we'll use in testing, demo-ing, serving etc..\n",
    "\n",
    "This model may contain non-PyTorch postprocessing (everything after the `unbatch`) which can come in handy\n",
    "when communicating with other bits of your infrastructure, such as returning results in the body of a response etc.. In this case, we add the results to a dictionary, along with the confidence estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26479a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model = (\n",
    "    preprocess\n",
    "    >> padl.batch\n",
    "    >> simplenet\n",
    "    >> padl.unbatch\n",
    "    >> padl.transform(lambda x: x.exp() / x.exp().sum())\n",
    "    >> padl.transform(lambda x: x.topk(1))\n",
    "    >> padl.transform(lambda x: {'probability': x[0].item(), 'prediction': x[1].item()})\n",
    ")\n",
    "infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f061d",
   "metadata": {},
   "source": [
    "In order to monitor performance, let's create a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y):\n",
    "    return sum([xx['prediction'] == yy for xx, yy in zip(x, y)]) / len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd80f3",
   "metadata": {},
   "source": [
    "The torch-extensions package contains a simple trainer, which may be configured to cover many use cases.\n",
    "In order to extend the trainer, the methods may be simply overwritten. Alternatively, simply create a new \n",
    "transform object, with methods to manage training, saving etc.. The `@padl.transform` decorator along with\n",
    "the methods `Transform.pre_load` and `Transform.post_load` will handle any important side effects which you\n",
    "need in order to save the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainer(\n",
    "    train_model=train_model,\n",
    "    infer_model=infer_model,\n",
    "    optimizer=torch.optim.Adam(train_model.pd_parameters()),\n",
    "    metrics={'accuracy': accuracy}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63bfa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_data = [x[0] for x in valid_data]\n",
    "ground_truth = [x[1] for x in valid_data]\n",
    "\n",
    "try:\n",
    "    t.train(train_data, 'train.padl', valid_data=valid_data,\n",
    "            save_interval=100, batch_size=100, metric_data=metric_data, ground_truth=ground_truth)\n",
    "except KeyboardInterrupt:\n",
    "    print('quitting training...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ecc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl import load\n",
    "\n",
    "s = load('train.padl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d637f4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    s.train(train_data, 'other.padl', save_interval=100)\n",
    "except KeyboardInterrupt:\n",
    "    print('quitting training')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = padl.load('other.padl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.infer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import random\n",
    "\n",
    "for _ in range(10):\n",
    "    datapoint = random.choice(metric_data)\n",
    "    display(datapoint)\n",
    "    print(r.infer_model.infer_apply(datapoint))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
